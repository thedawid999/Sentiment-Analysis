\chapter{Explorative Datenanalyse}
- irgendwas ...
----------------------------------------------
\section{Quelle/Herkunft}
- Amazon Reviews’23 Datensatz (McAuley Lab)
- Allgemeine Beschreibung des Datensatzes

\section{Datenumfang und Aufteilung}
- Kategorien: allbeauty, handmadeProducts und healthAndPersonalCare, da sie von der
Größe ähnlich sind (knapp 300MB) und unterschiedlich
AllBeauty - 701.528
HandmadeProducts - 664.162
HealthAndPersonalHealth - 494.121
- es gibt 10 verschiedene Spalten, hauptsächlich type object, aber auch DateTime
und 2 int64 für Rating und HelpfulVote, und bool bei verified\_purchase
- zum Glück gibts bei keiner Spalte fehlende Werte

\section{Verteilung der Bewertungen}
- AllBeauty mean bei 3.96
- HandmadeProducts mean bei 4.49
- HealthAndPersonalHealth mean bei 3.99
also sehr positiver Datensatz
- std ist bei allen auch nicht groß liegt bei 1.4 ungefähr
- die meisten Ratings sind 5, also später die Klassen ausgleichen, und
Datenmenge sowieso reduzieren
- wichtig zu erwähnen ist, dass bei handmade bei 5\% reviews der Einkauf nicht
verifiziert wurde, bei AllBeauty und Healthcare sind es sogar 10\%
- die Textlänge ist bis auf wenige Ausreißer bei AllBeauty und HealthCare gleich,
Handmade hat etwas kürze
- Bei Länge von Bewertungen, sieht man das min = 0 ist. D.h. obwohl es keine 
missing-values gab, gibt es trotzdem Bewertungen ohne Text, die man bei der
Vorverarbeitung entfernen muss



\chapter{Datenvorverarbeitung}
- irgendwas über Preprocessing
----------------------------------------------
\section{Data Cleaning}
- Datenmenge reduzieren und die Verteilung von Rating ausgleichen
- alle reviews löschen die nicht verifizierten Kauf haben
- alle mit Textlänge < 10 löschen
- alle spalten löschen die unnötig sind (es bleiben nur: rating, title, text)

\section{Textaufbereitung}
- Zusammenführung von Titel und Text
- lowercasing
- Tokenisierung
- Entfernen von Stoppwörtern
- Umgang mit Sonderzeichen (Punctuation)
- Lemmatization (langsamer, aber genauer als Stemming und das ist hier wichtiger)
- lemmatisierung ist bei default nur auf Nomen eingestellt, deswegen müssen wir 
zuerst ein POS-Tagging machen um jedes Wort mit der Wortart zu taggen.
Als erstens wird pos\_tag einen Tag zuweisen, danach muss man den - abhängig von
der Ausgabe - die richtige Kategorie an lemmatizer übergeben


\section{Numerische Repräsentation}
- zuerst alle 3 DF zusammenführen
- Verwendung von TF-IDF
    da viele Wörter redundant (product, use, one, etc.), hebt wichtige wörter 
    hervor (excellent, terrible, perfect)
    BoW zählt nur Wörter und beachtet keine Relevanz
- n\_gram auf 1,2 damit negationen erkannt werden
- einen kompletten dataframe fitten und transformieren

\section{Trennung von Eingabe- und Ausgabedaten}
- Definition der Zielvariable (numerische Bewertung)
    EINGABE (Features, X): Text = Titel + Beschreibung
    AUSGABE (Target, y):   Rating = 1, 2, 3, 4, 5 Sterne
    das vielleicht erst beim Modell und als Funktion! (text als eingabe und dann 
    die gleiche Reihenfolge wie bei Preprocessing)
- Aufteilung in Trainings- und Testsatz



\chapter{Modell und Methodik}
- Problemformulierung als Klassifikationsaufgabe
- Supervised Learning
- Mehrklassen-Klassifikation (5 Klassen)
----------------------------------------------
\section{Lineare Regression}
- [1] discriminative
- [1] kategorien selbst bestimmen
- Beschreibung des gewählten Klassifikators
- Begründung der Eignung für Textklassifikation

\section{Naive Bayes}
- [1] generative 
- [1] rechnet mit wahrscheinlichkeiten
- Beschreibung des gewählten Klassifikators
- Begründung der Eignung für Textklassifikation

VERGLEICH 
- Both methods are simple; Naive Bayes is the simplest one.
- Both methods are interpretable: you can look at the features which 
influenced the predictions most (in Naive Bayes - usually words, in logistic 
regression - whatever you defined).
- Naive Bayes is very fast to train - it requires only one pass through the 
training data to evaluate the counts. For logistic regression, this is not 
the case: you have to go over the data many times until the gradient ascent 
converges.
- Naive Bayes is too "naive" - it assumed that features (words) are 
conditionally independent given class. Logistic regression does not make this 
assumption - we can hope it is better.
- Both methods use manually defined feature representation (in Naive Bayes, 
BOW is the standard choice, but you still choose this yourself). While 
manually defined features are good for interpretability, they may be no so 
good for performance - you are likely to miss something which can be useful 
for the task.

\section{Trainingsprozess}
- Training auf dem Trainingsdatensatz
- Keine separate Validierungsmenge
- Begründung des Vorgehens



\chapter{Evaluation und Ergebnisse}
- irgendwas...
----------------------------------------------
\section{Evaluationsmetriken}
- Accuracy
- Confusion Matrix
- Begründung der Metrikauswahl

\section{Gesamtergebnisse}
- Accuracy auf dem Testsatz
- Darstellung und Interpretation der Confusion Matrix

\section{Ergebnisse nach Produktkategorien (optional)}
- Vergleich der Modellleistung zwischen Kategorien
- Kurze Analyse der Unterschiede

\section{Ergebnisse von zwei Algorithmen (optional)}
- Vergleich der Modellleistung zwischen Algorithmen (z.B. Naive Bayes und NN)
- Kurze Analyse der Unterschiede