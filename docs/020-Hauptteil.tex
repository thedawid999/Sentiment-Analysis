\chapter{Explorative Datenanalyse}
- irgendwas ...
----------------------------------------------
\section{Quelle/Herkunft}
- Amazon Reviews’23 Datensatz (McAuley Lab)
- Allgemeine Beschreibung des Datensatzes

\section{Datenumfang und Aufteilung}
- Kategorien: allbeauty, handmadeProducts und healthAndPersonalCare, da sie von der
Größe ähnlich sind (knapp 300MB) und unterschiedlich
AllBeauty - 701.528
HandmadeProducts - 664.162
HealthAndPersonalHealth - 494.121
- es gibt 10 verschiedene Spalten, hauptsächlich type object, aber auch DateTime
und 2 int64 für Rating und HelpfulVote, und bool bei verified\_purchase
- zum Glück gibts bei keiner Spalte fehlende Werte

\section{Verteilung der Bewertungen}
- AllBeauty mean bei 3.96
- HandmadeProducts mean bei 4.49
- HealthAndPersonalHealth mean bei 3.99
also sehr positiver Datensatz
- std ist bei allen auch nicht groß liegt bei 1.4 ungefähr
- die meisten Ratings sind 5, also muss man die später ausgleichen
- wichtig zu erwähnen ist, dass bei handmade bei 5\% reviews der Einkauf nicht
verifiziert wurde, bei AllBeauty und Healthcare sind es sogar 10\%



\chapter{Datenvorverarbeitung}
!!Daten reduzieren (so dass Rating gleich ist)
- irgendwas über Preprocessing
----------------------------------------------
\section{Trennung von Eingabe- und Ausgabedaten}
- Definition der Eingabedaten (Titel + Rezensionstext)
- Definition der Zielvariable (numerische Bewertung)
- Aufteilung in Trainings- und Testsatz

\section{Textaufbereitung}
- Zusammenführung von Titel und Text
- Tokenisierung
- Entfernen von Stoppwörtern
- Umgang mit Sonderzeichen und Groß-/Kleinschreibung

\section{Numerische Repräsentation}
- Verwendung von TF-IDF
- Wahl der n-Gramm-Länge (z. B. Unigramme)
- Begründung der Feature-Darstellung



\chapter{Modell und Methodik}
- Problemformulierung als Klassifikationsaufgabe
- Supervised Learning
- Mehrklassen-Klassifikation (5 Klassen)
----------------------------------------------
\section{Lineare Regression}
- [1] discriminative
- [1] kategorien selbst bestimmen
- Beschreibung des gewählten Klassifikators
- Begründung der Eignung für Textklassifikation

\section{Naive Bayes}
- [1] generative 
- [1] rechnet mit wahrscheinlichkeiten
- Beschreibung des gewählten Klassifikators
- Begründung der Eignung für Textklassifikation

VERGLEICH 
- Both methods are simple; Naive Bayes is the simplest one.
- Both methods are interpretable: you can look at the features which 
influenced the predictions most (in Naive Bayes - usually words, in logistic 
regression - whatever you defined).
- Naive Bayes is very fast to train - it requires only one pass through the 
training data to evaluate the counts. For logistic regression, this is not 
the case: you have to go over the data many times until the gradient ascent 
converges.
- Naive Bayes is too "naive" - it assumed that features (words) are 
conditionally independent given class. Logistic regression does not make this 
assumption - we can hope it is better.
- Both methods use manually defined feature representation (in Naive Bayes, 
BOW is the standard choice, but you still choose this yourself). While 
manually defined features are good for interpretability, they may be no so 
good for performance - you are likely to miss something which can be useful 
for the task.

\section{Trainingsprozess}
- Training auf dem Trainingsdatensatz
- Keine separate Validierungsmenge
- Begründung des Vorgehens



\chapter{Evaluation und Ergebnisse}
- irgendwas...
----------------------------------------------
\section{Evaluationsmetriken}
- Accuracy
- Confusion Matrix
- Begründung der Metrikauswahl

\section{Gesamtergebnisse}
- Accuracy auf dem Testsatz
- Darstellung und Interpretation der Confusion Matrix

\section{Ergebnisse nach Produktkategorien (optional)}
- Vergleich der Modellleistung zwischen Kategorien
- Kurze Analyse der Unterschiede

\section{Ergebnisse von zwei Algorithmen (optional)}
- Vergleich der Modellleistung zwischen Algorithmen (z.B. Naive Bayes und NN)
- Kurze Analyse der Unterschiede